{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import openai\n",
    "import pandas as pd\n",
    "import tiktoken  # For token counting\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the API key from config.py\n",
    "from config import get_openai_api_key\n",
    "\n",
    "# Set the OpenAI API key\n",
    "openai.api_key = get_openai_api_key()\n",
    "\n",
    "# Initialize the encoder for the gpt-4o model\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_tokens(text):\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def estimate_cost(total_tokens, model=\"gpt-4o\"):\n",
    "    # OpenAI pricing per 1,000 tokens\n",
    "    pricing = {\n",
    "        \"gpt-4o\": {\n",
    "            \"input\": 2.50 / 1000,     # $0.0025 per 1K input tokens\n",
    "            \"output\": 2.50 / 1000,    # $0.0025 per 1K output tokens\n",
    "        },\n",
    "        # Add other models and their pricing\n",
    "    }\n",
    "\n",
    "    model_pricing = pricing.get(model, {\"input\": 0.002, \"output\": 0.002})\n",
    "    cost = {\n",
    "        \"input\": (total_tokens['input'] / 1000) * model_pricing['input'],\n",
    "        \"output\": (total_tokens['output'] / 1000) * model_pricing['output'],\n",
    "        \"total\": 0\n",
    "    }\n",
    "    cost['total'] = cost['input'] + cost['output']\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(input_data):\n",
    "    if isinstance(input_data, list):\n",
    "        # If input is a list, convert it to a DataFrame\n",
    "        fund_df = pd.DataFrame({'fund_name': input_data})\n",
    "        fund_df['context'] = ''\n",
    "    elif isinstance(input_data, pd.DataFrame):\n",
    "        # Ask user for column names\n",
    "        print(\"Available columns:\", list(input_data.columns))\n",
    "        name_column = input(\"Enter the column name for fund names: \").strip()\n",
    "        context_columns = input(\"Enter additional context column names separated by commas (or leave blank): \").split(',')\n",
    "\n",
    "        # Clean up context columns list\n",
    "        context_columns = [col.strip() for col in context_columns if col.strip()]\n",
    "\n",
    "        # Ensure specified columns exist\n",
    "        required_columns = [name_column] + context_columns\n",
    "        for col in required_columns:\n",
    "            if col not in input_data.columns:\n",
    "                raise ValueError(f\"Column '{col}' not found in the DataFrame.\")\n",
    "\n",
    "        # Create a DataFrame with necessary columns\n",
    "        fund_df = input_data[required_columns].copy()\n",
    "\n",
    "        # Combine context columns into one if any\n",
    "        if context_columns:\n",
    "            fund_df['context'] = fund_df[context_columns].astype(str).agg(' '.join, axis=1)\n",
    "        else:\n",
    "            fund_df['context'] = ''\n",
    "        \n",
    "        fund_df.rename(columns={name_column: 'fund_name'}, inplace=True)\n",
    "    else:\n",
    "        raise ValueError(\"Input data must be a list or a pandas DataFrame.\")\n",
    "    \n",
    "    return fund_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(fund_df, classifications=None):\n",
    "    prompt = (\n",
    "        \"Classify the following funds into their respective fund types. \"\n",
    "        \"Use the provided classifications if applicable. \"\n",
    "        \"For each fund, return a JSON array with 'fund_name', 'classification', \"\n",
    "        \"and a 'reason' (less than 5 words) for the classification.\\n\\n\"\n",
    "    )\n",
    "    if classifications:\n",
    "        prompt += f\"Possible Classifications: {', '.join(classifications)}\\n\\n\"\n",
    "    prompt += \"Funds:\\n\"\n",
    "\n",
    "    for idx, row in fund_df.iterrows():\n",
    "        line = f\"{row['fund_name']}\"\n",
    "        if row['context']:\n",
    "            line += f\" | Context: {row['context']}\"\n",
    "        prompt += f\"{idx+1}. {line}\\n\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def classify_funds(fund_df, model=\"gpt-4o\", classifications=None):\n",
    "    # Create the prompt\n",
    "    prompt = create_prompt(fund_df, classifications)\n",
    "\n",
    "    # Estimate tokens for the prompt\n",
    "    prompt_tokens = estimate_tokens(prompt)\n",
    "\n",
    "    # Maximum allowed tokens for the model\n",
    "    max_context_length = 128000  # For gpt-4o\n",
    "    max_response_tokens = min(max_context_length - prompt_tokens, 2000)  # Limit max tokens for response\n",
    "\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=max_response_tokens,\n",
    "            temperature=0.0,\n",
    "        )\n",
    "\n",
    "        # Extract the assistant's reply\n",
    "        reply = response['choices'][0]['message']['content']\n",
    "        usage = response['usage']\n",
    "        return reply, usage\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing request: {e}\")\n",
    "        return None, {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}\n",
    "\n",
    "def parse_response(reply):\n",
    "    import json\n",
    "\n",
    "    try:\n",
    "        # Clean up the reply if necessary\n",
    "        reply = reply.strip()\n",
    "        # Load JSON from the reply\n",
    "        results = pd.read_json(reply)\n",
    "        return results\n",
    "    except ValueError as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        print(\"Raw reply:\", reply)\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated input tokens: 98\n",
      "Estimated output tokens: 500\n",
      "Estimated total cost: $0.0015\n",
      " - Input cost: $0.0002\n",
      " - Output cost: $0.0013\n",
      "Process halted due to estimated cost.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Input data can be a list or a DataFrame\n",
    "\n",
    "    input_data = [\"Global Equity Fund\", \"Emerging Markets Bond Fund\", \"Tech Growth Fund\"]\n",
    "\n",
    "    # Load and preprocess data\n",
    "    fund_df = load_data(input_data)\n",
    "\n",
    "    # Provide classifications if available\n",
    "    classifications = [\n",
    "        'Equity', 'Fixed Income', 'Balanced', 'Money Market',\n",
    "        'Commodity', 'Real Estate', 'Alternative Investments', 'Technology', 'Emerging Markets'\n",
    "    ]\n",
    "\n",
    "    # Estimate tokens and cost before proceeding\n",
    "    prompt = create_prompt(fund_df, classifications)\n",
    "    prompt_tokens = estimate_tokens(prompt)\n",
    "    # Estimate expected output tokens (adjust as needed)\n",
    "    estimated_output_tokens = 500\n",
    "    total_estimated_tokens = {'input': prompt_tokens, 'output': estimated_output_tokens}\n",
    "    estimated_cost = estimate_cost(total_estimated_tokens, model=\"gpt-4o\")\n",
    "\n",
    "    print(f\"Estimated input tokens: {total_estimated_tokens['input']}\")\n",
    "    print(f\"Estimated output tokens: {total_estimated_tokens['output']}\")\n",
    "    print(f\"Estimated total cost: ${estimated_cost['total']:.4f}\")\n",
    "    print(f\" - Input cost: ${estimated_cost['input']:.4f}\")\n",
    "    print(f\" - Output cost: ${estimated_cost['output']:.4f}\")\n",
    "\n",
    "    # Decide whether to proceed based on estimated cost\n",
    "    proceed = False  # Set to False if you want to halt based on cost\n",
    "    if proceed:\n",
    "        # Classify funds\n",
    "        reply, usage = classify_funds(fund_df, model=\"gpt-4o\", classifications=classifications)\n",
    "\n",
    "        # Update actual token usage\n",
    "        actual_tokens_used = {'input': usage['prompt_tokens'], 'output': usage['completion_tokens']}\n",
    "        actual_cost = estimate_cost(actual_tokens_used, model=\"gpt-4o\")\n",
    "        print(f\"Actual input tokens used: {actual_tokens_used['input']}\")\n",
    "        print(f\"Actual output tokens used: {actual_tokens_used['output']}\")\n",
    "        print(f\"Actual total cost: ${actual_cost['total']:.4f}\")\n",
    "        print(f\" - Input cost: ${actual_cost['input']:.4f}\")\n",
    "        print(f\" - Output cost: ${actual_cost['output']:.4f}\")\n",
    "\n",
    "        # Parse the response\n",
    "        final_df = parse_response(reply)\n",
    "\n",
    "        # Display the results\n",
    "        if not final_df.empty:\n",
    "            display(final_df)\n",
    "        else:\n",
    "            print(\"No results to display.\")\n",
    "    else:\n",
    "        print(\"Process halted due to estimated cost.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
